# ğŸ§  Depression Severity - Jigsaw Comment Classifier Challenge

An **NLP + Deep Learning project** to classify toxic and harmful comments across multiple categories using **BiGRU, DistilBERT, and RoBERTa**.  
Deployed as a **Streamlit web app with FastAPI backend** for real-time predictions.

---

## ğŸ“Œ Features
- ğŸ”¹ Multi-label classification of toxic comments (6 categories).  
- ğŸ”¹ Tackled **highly imbalanced dataset** with focal loss, weighted sampling & threshold tuning.  
- ğŸ”¹ Benchmarked multiple models:
  - **BiGRU baseline:** 70% precision / 70% recall  
  - **DistilBERT:** 80% / 80%  
  - **RoBERTa:** 75% precision / 85% recall  
- ğŸ”¹ Deployment-ready with **FastAPI + Streamlit**.  

---

## ğŸ“‚ Project Structure
Depression_Severity_Jigsaw_Comment_Classifier/
â”‚
â”œâ”€â”€ Deployment/ # FastAPI backend + Streamlit UI
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ ui.py
â”‚ â””â”€â”€ temp.py
â”‚
â”œâ”€â”€ Final_Modelling/ # Model training & notebooks
â”‚ â”œâ”€â”€ Data_Preparation.ipynb
â”‚ â”œâ”€â”€ roberta_bert.ipynb
â”‚ â”œâ”€â”€ prajwal_llms.ipynb
â”‚ â”œâ”€â”€ code_traditional.txt
â”‚ â””â”€â”€ ...
â”‚
â”œâ”€â”€ writng_code.py # helper script
â”œâ”€â”€ .gitignore # ignores datasets, models, checkpoints
â””â”€â”€ README.md

yaml
Copy code

---

## ğŸ“Š Models Tested
| Model        | Precision | Recall | Notes |
|--------------|-----------|--------|-------|
| BiGRU        | 70%       | 70%    | Baseline |
| DistilBERT   | 80%       | 80%    | Balanced performance |
| RoBERTa      | 75%       | 85%    | Higher recall (rare classes) |

---

## ğŸ“‚ Data & Models
âš ï¸ **Important:** Large datasets and model checkpoints are **not included** in this repo (ignored via `.gitignore`).  

### ğŸ”¹ Datasets
- Project uses **[Jigsaw Toxic Comment Classification Dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)** (Kaggle).  
- Download and place inside:
Datasets/
â”œâ”€â”€ train.csv
â”œâ”€â”€ test.csv
â””â”€â”€ ...

markdown
Copy code

### ğŸ”¹ Trained Models
- Fine-tuned models (e.g., `.pth`, `.safetensors`) are too large for GitHub.  
- Download from:
- Hugging Face: *[your-link-here]*  
- OR Google Drive: *[your-link-here]*  

Place inside:
Final_Modelling/
â”œâ”€â”€ best_model.pth
â”œâ”€â”€ best_model_bilstm.pth
â””â”€â”€ ...

yaml
Copy code

---

## â–¶ï¸ Running the Project

### 1ï¸âƒ£ Install requirements
```bash
pip install -r requirements.txt
2ï¸âƒ£ Start FastAPI backend
bash
Copy code
uvicorn Deployment.main:app --reload
3ï¸âƒ£ Start Streamlit UI
bash
Copy code
streamlit run Deployment/ui.py
Now open the local Streamlit link in your browser and test the toxicity classifier ğŸ‰

ğŸš€ Future Improvements
Optimize RoBERTa with mixed precision training (faster training).

Deploy with Docker + AWS/GCP.

Add explainability layer (SHAP/LIME) to interpret predictions.

ğŸ‘¨â€ğŸ’» Author
Ketan Gupta
ğŸ“§ Email 12212041ketanguptait@gmail.com
ğŸ’¼ LinkedIn https://www.linkedin.com/in/ketangupta41

â­ Contribute
Pull requests are welcome! For major changes, please open an issue first to discuss.
If you find this repo useful, donâ€™t forget to â­ star it!

yaml
Copy code

---

âœ¨ This README covers:  
- Overview with emojis for appeal.  
- Features & models.  
- Project structure.  
- Clear section on ignored files (**Datasets & Models**).  
- How to run.  
- Future scope + contribution.  

ğŸ‘‰ Do you want me to also generate a **`requirements.txt`** for your repo (with FastAPI, Streamlit, Transfo
